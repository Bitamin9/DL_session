{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training data:  60000\n",
      "number of test data  10000\n"
     ]
    }
   ],
   "source": [
    "#MNIST dataset\n",
    "\n",
    "train_dset = datasets.MNIST('../data', train=True, download=True,transform=transforms.ToTensor())\n",
    "\n",
    "test_dset = datasets.MNIST('../data', train=False,transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "print('number of training data: ', len(train_dset))\n",
    "print('number of test data ', len(test_dset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0706, 0.0706, 0.0706,\n",
       "          0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000, 0.9686, 0.4980,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.1176, 0.1412, 0.3686, 0.6039, 0.6667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9922, 0.8824, 0.6745, 0.9922, 0.9490, 0.7647, 0.2510,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922,\n",
       "          0.9333, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.9843, 0.3647, 0.3216, 0.3216, 0.2196, 0.1529, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137,\n",
       "          0.9686, 0.9451, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.3137, 0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000,\n",
       "          0.1686, 0.6039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451, 0.8824, 0.6275,\n",
       "          0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176, 0.9412, 0.9922,\n",
       "          0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1765, 0.7294,\n",
       "          0.9922, 0.9922, 0.5882, 0.1059, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0627,\n",
       "          0.3647, 0.9882, 0.9922, 0.7333, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.9765, 0.9922, 0.9765, 0.2510, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098,\n",
       "          0.7176, 0.9922, 0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922,\n",
       "          0.9922, 0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "          0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922, 0.7765,\n",
       "          0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.6706,\n",
       "          0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647, 0.3137, 0.0353,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.2157, 0.6745, 0.8863, 0.9922,\n",
       "          0.9922, 0.9922, 0.9922, 0.9569, 0.5216, 0.0431, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.5333, 0.9922, 0.9922, 0.9922,\n",
       "          0.8314, 0.5294, 0.5176, 0.0627, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "          0.0000, 0.0000, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image\n",
      "=========================================\n",
      "Shape of image\t:  torch.Size([1, 28, 28])\n",
      "10'th row of this image\t: tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2000, 0.9333, 0.9922, 0.9922, 0.7451, 0.4471, 0.9922, 0.8941,\n",
      "        0.1843, 0.3098, 1.0000, 0.6588, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000])\n",
      "Label\n",
      "=========================================\n",
      "label:  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#데이터 확인\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TODO: train_dset[*] 의 숫자값을 바꾸어 데이터를 다른 걸 출력해보자.\n",
    "\n",
    "\"\"\"\n",
    "image, label = train_dset[1] #image 해당값과 label 숫자 5가 나타남 \n",
    "\n",
    "print('Image')\n",
    "print('=========================================')\n",
    "print('Shape of image\\t: ', image.shape)\n",
    "print('10\\'th row of this image\\t:', image[0][9])\n",
    "\n",
    "print('Label')\n",
    "print('=========================================')\n",
    "print('label: ', label)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.squeeze().numpy() # squeeze는 차원을 1차원 줄여주는 역할 수행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "2. Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: batch_size 를 바꾸어보자 #batch_size가 의히마흔 바는 몇개를 불러올건지, \n",
    "\"\"\"\n",
    "train_loader = torch.utils.data.DataLoader(train_dset, batch_size = 16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size = 16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "def train(model, train_loader, optimizer, i_epoch, device):\n",
    "    model.train()\n",
    "    for i, (image, target) in enumerate(train_loader):\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "         #러닝 커브 그리기\n",
    "        loss_value.append(loss.detach().numpy())\n",
    "\n",
    "        #100번쨰 마다 loss 출력\n",
    "        if i%100==0:\n",
    "            print(\"epoch: {}, iteration: {}, loss: {}\".format(i_epoch, i, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "def test(model, test_loader, i_epoch, device):\n",
    "    model.eval()\n",
    "    accurate = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, target) in enumerate(test_loader):\n",
    "            image = image.to(device)\n",
    "            output = model(image)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            prediction = torch.argmax(output, dim=1)\n",
    "            accurate += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "\n",
    "    accuracy = accurate / len(test_loader.dataset)\n",
    "    #러닝커브 그리기\n",
    "    accuracy_value.append(accuracy)\n",
    "    print(\"epoch: {}, accuracy: {}\".format(i_epoch, accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "3. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TODO: 모델 Customization! 레이어 개수나 레이어 차원, 활성화 함수를 바꾸어보자.\n",
    "\n",
    "데이터의 형태를 주의하면서 바꾸어 볼 것~\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "            nn.Tanh()\n",
    "           )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss_value = []\n",
    "accuracy_value = []\n",
    "model = net()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TODO: 학습률을 바꾸어보고, Optimizer 을 바꾸어보자 (선택)\n",
    "\n",
    "\"\"\"\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 0, loss: 2.293759822845459\n",
      "epoch: 0, iteration: 100, loss: 1.885719895362854\n",
      "epoch: 0, iteration: 200, loss: 1.812931776046753\n",
      "epoch: 0, iteration: 300, loss: 1.5804420709609985\n",
      "epoch: 0, iteration: 400, loss: 1.4294534921646118\n",
      "epoch: 0, iteration: 500, loss: 1.4033290147781372\n",
      "epoch: 0, iteration: 600, loss: 1.247944951057434\n",
      "epoch: 0, iteration: 700, loss: 1.4689072370529175\n",
      "epoch: 0, iteration: 800, loss: 1.3552184104919434\n",
      "epoch: 0, iteration: 900, loss: 1.1470597982406616\n",
      "epoch: 0, iteration: 1000, loss: 1.1801272630691528\n",
      "epoch: 0, iteration: 1100, loss: 1.0638391971588135\n",
      "epoch: 0, iteration: 1200, loss: 1.3354520797729492\n",
      "epoch: 0, iteration: 1300, loss: 1.0925254821777344\n",
      "epoch: 0, iteration: 1400, loss: 1.2386170625686646\n",
      "epoch: 0, iteration: 1500, loss: 1.1851640939712524\n",
      "epoch: 0, iteration: 1600, loss: 1.0599088668823242\n",
      "epoch: 0, iteration: 1700, loss: 1.110439658164978\n",
      "epoch: 0, iteration: 1800, loss: 1.299127221107483\n",
      "epoch: 0, iteration: 1900, loss: 1.2521679401397705\n",
      "epoch: 0, iteration: 2000, loss: 1.2332667112350464\n",
      "epoch: 0, iteration: 2100, loss: 1.0516226291656494\n",
      "epoch: 0, iteration: 2200, loss: 0.9670414924621582\n",
      "epoch: 0, iteration: 2300, loss: 0.978823184967041\n",
      "epoch: 0, iteration: 2400, loss: 1.0136854648590088\n",
      "epoch: 0, iteration: 2500, loss: 1.0664209127426147\n",
      "epoch: 0, iteration: 2600, loss: 1.4034556150436401\n",
      "epoch: 0, iteration: 2700, loss: 1.1396526098251343\n",
      "epoch: 0, iteration: 2800, loss: 1.2141846418380737\n",
      "epoch: 0, iteration: 2900, loss: 0.9214857220649719\n",
      "epoch: 0, iteration: 3000, loss: 1.0463366508483887\n",
      "epoch: 0, iteration: 3100, loss: 1.0829366445541382\n",
      "epoch: 0, iteration: 3200, loss: 1.0084840059280396\n",
      "epoch: 0, iteration: 3300, loss: 1.1866360902786255\n",
      "epoch: 0, iteration: 3400, loss: 1.3084830045700073\n",
      "epoch: 0, iteration: 3500, loss: 0.9531981945037842\n",
      "epoch: 0, iteration: 3600, loss: 0.9243131875991821\n",
      "epoch: 0, iteration: 3700, loss: 1.0250877141952515\n",
      "epoch: 0, accuracy: 0.9061\n",
      "epoch: 1, iteration: 0, loss: 0.9415247440338135\n",
      "epoch: 1, iteration: 100, loss: 0.965429961681366\n",
      "epoch: 1, iteration: 200, loss: 0.9918672442436218\n",
      "epoch: 1, iteration: 300, loss: 1.0742650032043457\n",
      "epoch: 1, iteration: 400, loss: 1.0774122476577759\n",
      "epoch: 1, iteration: 500, loss: 1.0780819654464722\n",
      "epoch: 1, iteration: 600, loss: 1.0933213233947754\n",
      "epoch: 1, iteration: 700, loss: 1.05198335647583\n",
      "epoch: 1, iteration: 800, loss: 1.001250147819519\n",
      "epoch: 1, iteration: 900, loss: 1.0210084915161133\n",
      "epoch: 1, iteration: 1000, loss: 0.9493763446807861\n",
      "epoch: 1, iteration: 1100, loss: 1.0723271369934082\n",
      "epoch: 1, iteration: 1200, loss: 0.9361879229545593\n",
      "epoch: 1, iteration: 1300, loss: 1.023837685585022\n",
      "epoch: 1, iteration: 1400, loss: 1.0589625835418701\n",
      "epoch: 1, iteration: 1500, loss: 1.0657751560211182\n",
      "epoch: 1, iteration: 1600, loss: 1.0530519485473633\n",
      "epoch: 1, iteration: 1700, loss: 1.0159269571304321\n",
      "epoch: 1, iteration: 1800, loss: 0.9097530841827393\n",
      "epoch: 1, iteration: 1900, loss: 0.9287585020065308\n",
      "epoch: 1, iteration: 2000, loss: 1.1526436805725098\n",
      "epoch: 1, iteration: 2100, loss: 0.9457253217697144\n",
      "epoch: 1, iteration: 2200, loss: 0.9278602004051208\n",
      "epoch: 1, iteration: 2300, loss: 0.9859435558319092\n",
      "epoch: 1, iteration: 2400, loss: 0.9466487765312195\n",
      "epoch: 1, iteration: 2500, loss: 0.8715623021125793\n",
      "epoch: 1, iteration: 2600, loss: 1.1044049263000488\n",
      "epoch: 1, iteration: 2700, loss: 0.9893651008605957\n",
      "epoch: 1, iteration: 2800, loss: 1.0887254476547241\n",
      "epoch: 1, iteration: 2900, loss: 0.8923244476318359\n",
      "epoch: 1, iteration: 3000, loss: 1.0971252918243408\n",
      "epoch: 1, iteration: 3100, loss: 1.2361077070236206\n",
      "epoch: 1, iteration: 3200, loss: 1.097362995147705\n",
      "epoch: 1, iteration: 3300, loss: 1.1673071384429932\n",
      "epoch: 1, iteration: 3400, loss: 1.083272933959961\n",
      "epoch: 1, iteration: 3500, loss: 0.9318439960479736\n",
      "epoch: 1, iteration: 3600, loss: 0.956247866153717\n",
      "epoch: 1, iteration: 3700, loss: 0.918929934501648\n",
      "epoch: 1, accuracy: 0.9183\n",
      "epoch: 2, iteration: 0, loss: 0.9362038373947144\n",
      "epoch: 2, iteration: 100, loss: 0.8443361520767212\n",
      "epoch: 2, iteration: 200, loss: 1.0113704204559326\n",
      "epoch: 2, iteration: 300, loss: 0.9366175532341003\n",
      "epoch: 2, iteration: 400, loss: 0.936566948890686\n",
      "epoch: 2, iteration: 500, loss: 1.0528204441070557\n",
      "epoch: 2, iteration: 600, loss: 0.9758639931678772\n",
      "epoch: 2, iteration: 700, loss: 0.9512122869491577\n",
      "epoch: 2, iteration: 800, loss: 1.0795706510543823\n",
      "epoch: 2, iteration: 900, loss: 1.0019047260284424\n",
      "epoch: 2, iteration: 1000, loss: 1.0580406188964844\n",
      "epoch: 2, iteration: 1100, loss: 0.9922727942466736\n",
      "epoch: 2, iteration: 1200, loss: 1.0775158405303955\n",
      "epoch: 2, iteration: 1300, loss: 0.955616295337677\n",
      "epoch: 2, iteration: 1400, loss: 0.8722611665725708\n",
      "epoch: 2, iteration: 1500, loss: 0.8926010727882385\n",
      "epoch: 2, iteration: 1600, loss: 1.1590865850448608\n",
      "epoch: 2, iteration: 1700, loss: 0.8556776642799377\n",
      "epoch: 2, iteration: 1800, loss: 0.9426842331886292\n",
      "epoch: 2, iteration: 1900, loss: 1.0275614261627197\n",
      "epoch: 2, iteration: 2000, loss: 0.8856874704360962\n",
      "epoch: 2, iteration: 2100, loss: 0.8574849963188171\n",
      "epoch: 2, iteration: 2200, loss: 1.14212965965271\n",
      "epoch: 2, iteration: 2300, loss: 1.0622100830078125\n",
      "epoch: 2, iteration: 2400, loss: 0.9121215343475342\n",
      "epoch: 2, iteration: 2500, loss: 0.8497951626777649\n",
      "epoch: 2, iteration: 2600, loss: 0.9668219685554504\n",
      "epoch: 2, iteration: 2700, loss: 0.860761821269989\n",
      "epoch: 2, iteration: 2800, loss: 0.8180307745933533\n",
      "epoch: 2, iteration: 2900, loss: 1.0791290998458862\n",
      "epoch: 2, iteration: 3000, loss: 0.8783029913902283\n",
      "epoch: 2, iteration: 3100, loss: 0.8873996734619141\n",
      "epoch: 2, iteration: 3200, loss: 0.8238229751586914\n",
      "epoch: 2, iteration: 3300, loss: 1.1188145875930786\n",
      "epoch: 2, iteration: 3400, loss: 0.8725078701972961\n",
      "epoch: 2, iteration: 3500, loss: 1.210720181465149\n",
      "epoch: 2, iteration: 3600, loss: 0.8530279994010925\n",
      "epoch: 2, iteration: 3700, loss: 0.9099701046943665\n",
      "epoch: 2, accuracy: 0.9261\n",
      "epoch: 3, iteration: 0, loss: 0.8692773580551147\n",
      "epoch: 3, iteration: 100, loss: 0.9455678462982178\n",
      "epoch: 3, iteration: 200, loss: 0.8377036452293396\n",
      "epoch: 3, iteration: 300, loss: 0.859995424747467\n",
      "epoch: 3, iteration: 400, loss: 0.8373503088951111\n",
      "epoch: 3, iteration: 500, loss: 0.8578038215637207\n",
      "epoch: 3, iteration: 600, loss: 0.8780222535133362\n",
      "epoch: 3, iteration: 700, loss: 0.8318501710891724\n",
      "epoch: 3, iteration: 800, loss: 0.8656222224235535\n",
      "epoch: 3, iteration: 900, loss: 1.0196499824523926\n",
      "epoch: 3, iteration: 1000, loss: 0.9554383754730225\n",
      "epoch: 3, iteration: 1100, loss: 0.8719704151153564\n",
      "epoch: 3, iteration: 1200, loss: 0.9779157042503357\n",
      "epoch: 3, iteration: 1300, loss: 1.0851675271987915\n",
      "epoch: 3, iteration: 1400, loss: 1.0416628122329712\n",
      "epoch: 3, iteration: 1500, loss: 0.8601201176643372\n",
      "epoch: 3, iteration: 1600, loss: 0.821889340877533\n",
      "epoch: 3, iteration: 1700, loss: 0.9728773236274719\n",
      "epoch: 3, iteration: 1800, loss: 0.8811856508255005\n",
      "epoch: 3, iteration: 1900, loss: 0.8240064382553101\n",
      "epoch: 3, iteration: 2000, loss: 0.8957269787788391\n",
      "epoch: 3, iteration: 2100, loss: 0.8561115860939026\n",
      "epoch: 3, iteration: 2200, loss: 0.9462119340896606\n",
      "epoch: 3, iteration: 2300, loss: 1.1314380168914795\n",
      "epoch: 3, iteration: 2400, loss: 0.948317289352417\n",
      "epoch: 3, iteration: 2500, loss: 0.9283750653266907\n",
      "epoch: 3, iteration: 2600, loss: 0.9317622184753418\n",
      "epoch: 3, iteration: 2700, loss: 0.9452511668205261\n",
      "epoch: 3, iteration: 2800, loss: 0.8975950479507446\n",
      "epoch: 3, iteration: 2900, loss: 0.9060704112052917\n",
      "epoch: 3, iteration: 3000, loss: 0.8685771226882935\n",
      "epoch: 3, iteration: 3100, loss: 1.157170295715332\n",
      "epoch: 3, iteration: 3200, loss: 1.0919240713119507\n",
      "epoch: 3, iteration: 3300, loss: 0.8806527853012085\n",
      "epoch: 3, iteration: 3400, loss: 0.9823676943778992\n",
      "epoch: 3, iteration: 3500, loss: 0.8783271908760071\n",
      "epoch: 3, iteration: 3600, loss: 1.1678658723831177\n",
      "epoch: 3, iteration: 3700, loss: 0.8543615341186523\n",
      "epoch: 3, accuracy: 0.9326\n",
      "epoch: 4, iteration: 0, loss: 0.9287575483322144\n",
      "epoch: 4, iteration: 100, loss: 0.8913177251815796\n",
      "epoch: 4, iteration: 200, loss: 1.270082712173462\n",
      "epoch: 4, iteration: 300, loss: 0.9604188203811646\n",
      "epoch: 4, iteration: 400, loss: 0.8487761616706848\n",
      "epoch: 4, iteration: 500, loss: 0.9007923603057861\n",
      "epoch: 4, iteration: 600, loss: 0.8400105237960815\n",
      "epoch: 4, iteration: 700, loss: 0.8885105848312378\n",
      "epoch: 4, iteration: 800, loss: 1.087405800819397\n",
      "epoch: 4, iteration: 900, loss: 0.8704588413238525\n",
      "epoch: 4, iteration: 1000, loss: 1.0318806171417236\n",
      "epoch: 4, iteration: 1100, loss: 0.9679102897644043\n",
      "epoch: 4, iteration: 1200, loss: 0.8619273900985718\n",
      "epoch: 4, iteration: 1300, loss: 0.9163856506347656\n",
      "epoch: 4, iteration: 1400, loss: 0.888468861579895\n",
      "epoch: 4, iteration: 1500, loss: 1.0054441690444946\n",
      "epoch: 4, iteration: 1600, loss: 0.9358862638473511\n",
      "epoch: 4, iteration: 1700, loss: 0.9025599360466003\n",
      "epoch: 4, iteration: 1800, loss: 0.9325879812240601\n",
      "epoch: 4, iteration: 1900, loss: 0.9343311786651611\n",
      "epoch: 4, iteration: 2000, loss: 1.0589306354522705\n",
      "epoch: 4, iteration: 2100, loss: 0.907504141330719\n",
      "epoch: 4, iteration: 2200, loss: 1.0234469175338745\n",
      "epoch: 4, iteration: 2300, loss: 0.8430694341659546\n",
      "epoch: 4, iteration: 2400, loss: 0.9478918313980103\n",
      "epoch: 4, iteration: 2500, loss: 0.9453642964363098\n",
      "epoch: 4, iteration: 2600, loss: 0.9165442585945129\n",
      "epoch: 4, iteration: 2700, loss: 0.9420566558837891\n",
      "epoch: 4, iteration: 2800, loss: 0.86365807056427\n",
      "epoch: 4, iteration: 2900, loss: 0.9223567843437195\n",
      "epoch: 4, iteration: 3000, loss: 0.8856089115142822\n",
      "epoch: 4, iteration: 3100, loss: 0.865049421787262\n",
      "epoch: 4, iteration: 3200, loss: 1.0976511240005493\n",
      "epoch: 4, iteration: 3300, loss: 0.8344215154647827\n",
      "epoch: 4, iteration: 3400, loss: 0.8272743821144104\n",
      "epoch: 4, iteration: 3500, loss: 1.1259572505950928\n",
      "epoch: 4, iteration: 3600, loss: 0.8802669048309326\n",
      "epoch: 4, iteration: 3700, loss: 1.0251859426498413\n",
      "epoch: 4, accuracy: 0.9362\n",
      "epoch: 5, iteration: 0, loss: 0.9173179864883423\n",
      "epoch: 5, iteration: 100, loss: 0.8223097324371338\n",
      "epoch: 5, iteration: 200, loss: 0.8573103547096252\n",
      "epoch: 5, iteration: 300, loss: 1.080215573310852\n",
      "epoch: 5, iteration: 400, loss: 0.9718082547187805\n",
      "epoch: 5, iteration: 500, loss: 0.9205367565155029\n",
      "epoch: 5, iteration: 600, loss: 0.9155527949333191\n",
      "epoch: 5, iteration: 700, loss: 0.9277165532112122\n",
      "epoch: 5, iteration: 800, loss: 0.8355969190597534\n",
      "epoch: 5, iteration: 900, loss: 0.8648366332054138\n",
      "epoch: 5, iteration: 1000, loss: 0.9813088774681091\n",
      "epoch: 5, iteration: 1100, loss: 0.9551368355751038\n",
      "epoch: 5, iteration: 1200, loss: 1.0693827867507935\n",
      "epoch: 5, iteration: 1300, loss: 0.8563462495803833\n",
      "epoch: 5, iteration: 1400, loss: 0.8769226670265198\n",
      "epoch: 5, iteration: 1500, loss: 1.0598891973495483\n",
      "epoch: 5, iteration: 1600, loss: 0.9488973021507263\n",
      "epoch: 5, iteration: 1700, loss: 0.8866469860076904\n",
      "epoch: 5, iteration: 1800, loss: 0.8953409194946289\n",
      "epoch: 5, iteration: 1900, loss: 0.9206164479255676\n",
      "epoch: 5, iteration: 2000, loss: 0.8476324081420898\n",
      "epoch: 5, iteration: 2100, loss: 0.9105275869369507\n",
      "epoch: 5, iteration: 2200, loss: 0.8323773741722107\n",
      "epoch: 5, iteration: 2300, loss: 0.870844841003418\n",
      "epoch: 5, iteration: 2400, loss: 0.8973729014396667\n",
      "epoch: 5, iteration: 2500, loss: 0.8353083729743958\n",
      "epoch: 5, iteration: 2600, loss: 0.975727379322052\n",
      "epoch: 5, iteration: 2700, loss: 0.9346714019775391\n",
      "epoch: 5, iteration: 2800, loss: 0.8446376323699951\n",
      "epoch: 5, iteration: 2900, loss: 1.0956240892410278\n",
      "epoch: 5, iteration: 3000, loss: 0.9044914245605469\n",
      "epoch: 5, iteration: 3100, loss: 1.1966253519058228\n",
      "epoch: 5, iteration: 3200, loss: 0.8581377267837524\n",
      "epoch: 5, iteration: 3300, loss: 0.9973748326301575\n",
      "epoch: 5, iteration: 3400, loss: 0.8715134263038635\n",
      "epoch: 5, iteration: 3500, loss: 0.8520429730415344\n",
      "epoch: 5, iteration: 3600, loss: 0.905805230140686\n",
      "epoch: 5, iteration: 3700, loss: 1.1756398677825928\n",
      "epoch: 5, accuracy: 0.9371\n",
      "epoch: 6, iteration: 0, loss: 0.9647603631019592\n",
      "epoch: 6, iteration: 100, loss: 0.9127916097640991\n",
      "epoch: 6, iteration: 200, loss: 0.9593432545661926\n",
      "epoch: 6, iteration: 300, loss: 0.9327030181884766\n",
      "epoch: 6, iteration: 400, loss: 0.8449894785881042\n",
      "epoch: 6, iteration: 500, loss: 0.9768581390380859\n",
      "epoch: 6, iteration: 600, loss: 0.8838764429092407\n",
      "epoch: 6, iteration: 700, loss: 0.8364022970199585\n",
      "epoch: 6, iteration: 800, loss: 0.8798868656158447\n",
      "epoch: 6, iteration: 900, loss: 0.8892531991004944\n",
      "epoch: 6, iteration: 1000, loss: 0.8412125706672668\n",
      "epoch: 6, iteration: 1100, loss: 0.8296386003494263\n",
      "epoch: 6, iteration: 1200, loss: 0.8942914009094238\n",
      "epoch: 6, iteration: 1300, loss: 0.9125264286994934\n",
      "epoch: 6, iteration: 1400, loss: 0.8482785224914551\n",
      "epoch: 6, iteration: 1500, loss: 0.9158295392990112\n",
      "epoch: 6, iteration: 1600, loss: 1.0610123872756958\n",
      "epoch: 6, iteration: 1700, loss: 0.8956896066665649\n",
      "epoch: 6, iteration: 1800, loss: 0.8793896436691284\n",
      "epoch: 6, iteration: 1900, loss: 0.8551682829856873\n",
      "epoch: 6, iteration: 2000, loss: 0.982615053653717\n",
      "epoch: 6, iteration: 2100, loss: 0.9791796207427979\n",
      "epoch: 6, iteration: 2200, loss: 0.8465930223464966\n",
      "epoch: 6, iteration: 2300, loss: 0.9759328961372375\n",
      "epoch: 6, iteration: 2400, loss: 0.9654263257980347\n",
      "epoch: 6, iteration: 2500, loss: 0.8435507416725159\n",
      "epoch: 6, iteration: 2600, loss: 0.8854730129241943\n",
      "epoch: 6, iteration: 2700, loss: 0.8173725008964539\n",
      "epoch: 6, iteration: 2800, loss: 0.8170953392982483\n",
      "epoch: 6, iteration: 2900, loss: 0.892052173614502\n",
      "epoch: 6, iteration: 3000, loss: 1.0468089580535889\n",
      "epoch: 6, iteration: 3100, loss: 0.835989773273468\n",
      "epoch: 6, iteration: 3200, loss: 0.8808407187461853\n",
      "epoch: 6, iteration: 3300, loss: 0.8786938786506653\n",
      "epoch: 6, iteration: 3400, loss: 1.00555419921875\n",
      "epoch: 6, iteration: 3500, loss: 0.9259727597236633\n",
      "epoch: 6, iteration: 3600, loss: 0.8314014673233032\n",
      "epoch: 6, iteration: 3700, loss: 1.050478219985962\n",
      "epoch: 6, accuracy: 0.9424\n",
      "epoch: 7, iteration: 0, loss: 0.8240295648574829\n",
      "epoch: 7, iteration: 100, loss: 0.9580435156822205\n",
      "epoch: 7, iteration: 200, loss: 0.9638901948928833\n",
      "epoch: 7, iteration: 300, loss: 1.0313738584518433\n",
      "epoch: 7, iteration: 400, loss: 0.861144483089447\n",
      "epoch: 7, iteration: 500, loss: 0.9750069379806519\n",
      "epoch: 7, iteration: 600, loss: 0.8626049160957336\n",
      "epoch: 7, iteration: 700, loss: 0.9388549327850342\n",
      "epoch: 7, iteration: 800, loss: 0.848297119140625\n",
      "epoch: 7, iteration: 900, loss: 0.9255273938179016\n",
      "epoch: 7, iteration: 1000, loss: 0.9659339785575867\n",
      "epoch: 7, iteration: 1100, loss: 0.8677971959114075\n",
      "epoch: 7, iteration: 1200, loss: 0.8413689732551575\n",
      "epoch: 7, iteration: 1300, loss: 1.0205482244491577\n",
      "epoch: 7, iteration: 1400, loss: 0.8674825429916382\n",
      "epoch: 7, iteration: 1500, loss: 0.8452796936035156\n",
      "epoch: 7, iteration: 1600, loss: 0.8308026790618896\n",
      "epoch: 7, iteration: 1700, loss: 0.9236664175987244\n",
      "epoch: 7, iteration: 1800, loss: 0.8382349610328674\n",
      "epoch: 7, iteration: 1900, loss: 0.9183118939399719\n",
      "epoch: 7, iteration: 2000, loss: 0.9768203496932983\n",
      "epoch: 7, iteration: 2100, loss: 1.013231635093689\n",
      "epoch: 7, iteration: 2200, loss: 0.8032314777374268\n",
      "epoch: 7, iteration: 2300, loss: 0.9619754552841187\n",
      "epoch: 7, iteration: 2400, loss: 0.8241896033287048\n",
      "epoch: 7, iteration: 2500, loss: 0.8162016868591309\n",
      "epoch: 7, iteration: 2600, loss: 0.9600760340690613\n",
      "epoch: 7, iteration: 2700, loss: 1.0266051292419434\n",
      "epoch: 7, iteration: 2800, loss: 0.8166224360466003\n",
      "epoch: 7, iteration: 2900, loss: 0.8263345956802368\n",
      "epoch: 7, iteration: 3000, loss: 1.0389957427978516\n",
      "epoch: 7, iteration: 3100, loss: 0.836628794670105\n",
      "epoch: 7, iteration: 3200, loss: 0.851712167263031\n",
      "epoch: 7, iteration: 3300, loss: 0.8204879760742188\n",
      "epoch: 7, iteration: 3400, loss: 0.8531853556632996\n",
      "epoch: 7, iteration: 3500, loss: 1.1612133979797363\n",
      "epoch: 7, iteration: 3600, loss: 0.8611763119697571\n",
      "epoch: 7, iteration: 3700, loss: 0.825473427772522\n",
      "epoch: 7, accuracy: 0.9452\n",
      "epoch: 8, iteration: 0, loss: 0.8063514828681946\n",
      "epoch: 8, iteration: 100, loss: 0.8691335320472717\n",
      "epoch: 8, iteration: 200, loss: 1.1069769859313965\n",
      "epoch: 8, iteration: 300, loss: 0.8270425796508789\n",
      "epoch: 8, iteration: 400, loss: 0.81158047914505\n",
      "epoch: 8, iteration: 500, loss: 0.8829797506332397\n",
      "epoch: 8, iteration: 600, loss: 0.9885678887367249\n",
      "epoch: 8, iteration: 700, loss: 0.9138764142990112\n",
      "epoch: 8, iteration: 800, loss: 0.9264614582061768\n",
      "epoch: 8, iteration: 900, loss: 0.9524996280670166\n",
      "epoch: 8, iteration: 1000, loss: 0.8285371661186218\n",
      "epoch: 8, iteration: 1100, loss: 0.903552770614624\n",
      "epoch: 8, iteration: 1200, loss: 0.8229981064796448\n",
      "epoch: 8, iteration: 1300, loss: 0.8934763669967651\n",
      "epoch: 8, iteration: 1400, loss: 0.8720340728759766\n",
      "epoch: 8, iteration: 1500, loss: 0.8306451439857483\n",
      "epoch: 8, iteration: 1600, loss: 0.8133155107498169\n",
      "epoch: 8, iteration: 1700, loss: 0.8466230630874634\n",
      "epoch: 8, iteration: 1800, loss: 0.8511485457420349\n",
      "epoch: 8, iteration: 1900, loss: 0.9066053032875061\n",
      "epoch: 8, iteration: 2000, loss: 0.9112406969070435\n",
      "epoch: 8, iteration: 2100, loss: 1.0498688220977783\n",
      "epoch: 8, iteration: 2200, loss: 1.039655327796936\n",
      "epoch: 8, iteration: 2300, loss: 0.8139117956161499\n",
      "epoch: 8, iteration: 2400, loss: 0.9284800291061401\n",
      "epoch: 8, iteration: 2500, loss: 0.8499422669410706\n",
      "epoch: 8, iteration: 2600, loss: 0.9327690601348877\n",
      "epoch: 8, iteration: 2700, loss: 0.8521516919136047\n",
      "epoch: 8, iteration: 2800, loss: 0.8753440380096436\n",
      "epoch: 8, iteration: 2900, loss: 0.852085292339325\n",
      "epoch: 8, iteration: 3000, loss: 0.9249981641769409\n",
      "epoch: 8, iteration: 3100, loss: 0.9937678575515747\n",
      "epoch: 8, iteration: 3200, loss: 0.8271360397338867\n",
      "epoch: 8, iteration: 3300, loss: 0.9817927479743958\n",
      "epoch: 8, iteration: 3400, loss: 0.8222463726997375\n",
      "epoch: 8, iteration: 3500, loss: 0.8144574761390686\n",
      "epoch: 8, iteration: 3600, loss: 0.8187326788902283\n",
      "epoch: 8, iteration: 3700, loss: 0.9361144304275513\n",
      "epoch: 8, accuracy: 0.9468\n",
      "epoch: 9, iteration: 0, loss: 0.8883543014526367\n",
      "epoch: 9, iteration: 100, loss: 0.8091019988059998\n",
      "epoch: 9, iteration: 200, loss: 0.8383973836898804\n",
      "epoch: 9, iteration: 300, loss: 0.8210633993148804\n",
      "epoch: 9, iteration: 400, loss: 0.8707197308540344\n",
      "epoch: 9, iteration: 500, loss: 0.815342366695404\n",
      "epoch: 9, iteration: 600, loss: 0.9504094123840332\n",
      "epoch: 9, iteration: 700, loss: 0.8029406666755676\n",
      "epoch: 9, iteration: 800, loss: 0.8630470037460327\n",
      "epoch: 9, iteration: 900, loss: 0.810846209526062\n",
      "epoch: 9, iteration: 1000, loss: 0.850136399269104\n",
      "epoch: 9, iteration: 1100, loss: 0.8305357694625854\n",
      "epoch: 9, iteration: 1200, loss: 0.8646234273910522\n",
      "epoch: 9, iteration: 1300, loss: 0.8136218786239624\n",
      "epoch: 9, iteration: 1400, loss: 0.825965166091919\n",
      "epoch: 9, iteration: 1500, loss: 1.137273907661438\n",
      "epoch: 9, iteration: 1600, loss: 0.875288724899292\n",
      "epoch: 9, iteration: 1700, loss: 0.9367737770080566\n",
      "epoch: 9, iteration: 1800, loss: 0.9356513619422913\n",
      "epoch: 9, iteration: 1900, loss: 0.8383135199546814\n",
      "epoch: 9, iteration: 2000, loss: 0.8518245220184326\n",
      "epoch: 9, iteration: 2100, loss: 0.8340578675270081\n",
      "epoch: 9, iteration: 2200, loss: 0.8418600559234619\n",
      "epoch: 9, iteration: 2300, loss: 0.8422908782958984\n",
      "epoch: 9, iteration: 2400, loss: 0.9544340968132019\n",
      "epoch: 9, iteration: 2500, loss: 0.9325025677680969\n",
      "epoch: 9, iteration: 2600, loss: 0.8554243445396423\n",
      "epoch: 9, iteration: 2700, loss: 0.9740363955497742\n",
      "epoch: 9, iteration: 2800, loss: 0.8494830131530762\n",
      "epoch: 9, iteration: 2900, loss: 0.9245831966400146\n",
      "epoch: 9, iteration: 3000, loss: 0.8056471943855286\n",
      "epoch: 9, iteration: 3100, loss: 0.8620561361312866\n",
      "epoch: 9, iteration: 3200, loss: 0.8122375011444092\n",
      "epoch: 9, iteration: 3300, loss: 0.816867470741272\n",
      "epoch: 9, iteration: 3400, loss: 1.0935994386672974\n",
      "epoch: 9, iteration: 3500, loss: 0.8329826593399048\n",
      "epoch: 9, iteration: 3600, loss: 0.8563390970230103\n",
      "epoch: 9, iteration: 3700, loss: 0.8452697992324829\n",
      "epoch: 9, accuracy: 0.949\n",
      "epoch: 10, iteration: 0, loss: 0.8902177810668945\n",
      "epoch: 10, iteration: 100, loss: 0.8551316261291504\n",
      "epoch: 10, iteration: 200, loss: 0.8106517195701599\n",
      "epoch: 10, iteration: 300, loss: 0.829948365688324\n",
      "epoch: 10, iteration: 400, loss: 0.8568008542060852\n",
      "epoch: 10, iteration: 500, loss: 0.8136186003684998\n",
      "epoch: 10, iteration: 600, loss: 0.82468181848526\n",
      "epoch: 10, iteration: 700, loss: 0.8275046944618225\n",
      "epoch: 10, iteration: 800, loss: 1.0639721155166626\n",
      "epoch: 10, iteration: 900, loss: 0.9509156346321106\n",
      "epoch: 10, iteration: 1000, loss: 0.9681308269500732\n",
      "epoch: 10, iteration: 1100, loss: 0.8587145209312439\n",
      "epoch: 10, iteration: 1200, loss: 1.026880145072937\n",
      "epoch: 10, iteration: 1300, loss: 0.8249565958976746\n",
      "epoch: 10, iteration: 1400, loss: 0.9929076433181763\n",
      "epoch: 10, iteration: 1500, loss: 0.8952540755271912\n",
      "epoch: 10, iteration: 1600, loss: 0.8669413924217224\n",
      "epoch: 10, iteration: 1700, loss: 0.8650756478309631\n",
      "epoch: 10, iteration: 1800, loss: 0.8890030980110168\n",
      "epoch: 10, iteration: 1900, loss: 0.8750953078269958\n",
      "epoch: 10, iteration: 2000, loss: 0.9798388481140137\n",
      "epoch: 10, iteration: 2100, loss: 0.9868174195289612\n",
      "epoch: 10, iteration: 2200, loss: 0.9175564050674438\n",
      "epoch: 10, iteration: 2300, loss: 0.8285070657730103\n",
      "epoch: 10, iteration: 2400, loss: 0.7998084425926208\n",
      "epoch: 10, iteration: 2500, loss: 0.8505721688270569\n",
      "epoch: 10, iteration: 2600, loss: 0.9000252485275269\n",
      "epoch: 10, iteration: 2700, loss: 0.9087655544281006\n",
      "epoch: 10, iteration: 2800, loss: 0.8528038859367371\n",
      "epoch: 10, iteration: 2900, loss: 1.0849251747131348\n",
      "epoch: 10, iteration: 3000, loss: 0.866687536239624\n",
      "epoch: 10, iteration: 3100, loss: 0.9713831543922424\n",
      "epoch: 10, iteration: 3200, loss: 0.844672441482544\n",
      "epoch: 10, iteration: 3300, loss: 0.8624431490898132\n",
      "epoch: 10, iteration: 3400, loss: 0.8555625081062317\n",
      "epoch: 10, iteration: 3500, loss: 0.8489421606063843\n",
      "epoch: 10, iteration: 3600, loss: 0.8046485185623169\n",
      "epoch: 10, iteration: 3700, loss: 0.8514757752418518\n",
      "epoch: 10, accuracy: 0.9523\n",
      "epoch: 11, iteration: 0, loss: 0.8206571340560913\n",
      "epoch: 11, iteration: 100, loss: 0.8345074653625488\n",
      "epoch: 11, iteration: 200, loss: 0.9794713258743286\n",
      "epoch: 11, iteration: 300, loss: 0.8242406845092773\n",
      "epoch: 11, iteration: 400, loss: 0.8308768272399902\n",
      "epoch: 11, iteration: 500, loss: 0.8023653030395508\n",
      "epoch: 11, iteration: 600, loss: 0.8193511366844177\n",
      "epoch: 11, iteration: 700, loss: 0.8309343457221985\n",
      "epoch: 11, iteration: 800, loss: 0.8364126086235046\n",
      "epoch: 11, iteration: 900, loss: 0.931261420249939\n",
      "epoch: 11, iteration: 1000, loss: 0.9194430112838745\n",
      "epoch: 11, iteration: 1100, loss: 0.8194491267204285\n",
      "epoch: 11, iteration: 1200, loss: 0.8439621329307556\n",
      "epoch: 11, iteration: 1300, loss: 0.9617148041725159\n",
      "epoch: 11, iteration: 1400, loss: 0.8183150291442871\n",
      "epoch: 11, iteration: 1500, loss: 0.9400219917297363\n",
      "epoch: 11, iteration: 1600, loss: 0.8158408999443054\n",
      "epoch: 11, iteration: 1700, loss: 0.9532952904701233\n",
      "epoch: 11, iteration: 1800, loss: 0.9019085168838501\n",
      "epoch: 11, iteration: 1900, loss: 0.9146978855133057\n",
      "epoch: 11, iteration: 2000, loss: 0.8492931127548218\n",
      "epoch: 11, iteration: 2100, loss: 0.8190662860870361\n",
      "epoch: 11, iteration: 2200, loss: 0.8805506229400635\n",
      "epoch: 11, iteration: 2300, loss: 0.8419376611709595\n",
      "epoch: 11, iteration: 2400, loss: 0.8557673096656799\n",
      "epoch: 11, iteration: 2500, loss: 0.9621198177337646\n",
      "epoch: 11, iteration: 2600, loss: 0.9206563234329224\n",
      "epoch: 11, iteration: 2700, loss: 1.0007811784744263\n",
      "epoch: 11, iteration: 2800, loss: 0.81026691198349\n",
      "epoch: 11, iteration: 2900, loss: 0.8510287404060364\n",
      "epoch: 11, iteration: 3000, loss: 0.7981953620910645\n",
      "epoch: 11, iteration: 3100, loss: 0.8977756500244141\n",
      "epoch: 11, iteration: 3200, loss: 0.9281010031700134\n",
      "epoch: 11, iteration: 3300, loss: 0.8407931327819824\n",
      "epoch: 11, iteration: 3400, loss: 0.837727427482605\n",
      "epoch: 11, iteration: 3500, loss: 0.8795903921127319\n",
      "epoch: 11, iteration: 3600, loss: 0.8091379404067993\n",
      "epoch: 11, iteration: 3700, loss: 0.8648611903190613\n",
      "epoch: 11, accuracy: 0.9546\n",
      "epoch: 12, iteration: 0, loss: 0.846790075302124\n",
      "epoch: 12, iteration: 100, loss: 0.8168277740478516\n",
      "epoch: 12, iteration: 200, loss: 0.9075149893760681\n",
      "epoch: 12, iteration: 300, loss: 0.8458709120750427\n",
      "epoch: 12, iteration: 400, loss: 0.931354820728302\n",
      "epoch: 12, iteration: 500, loss: 0.9547839760780334\n",
      "epoch: 12, iteration: 600, loss: 0.8697342276573181\n",
      "epoch: 12, iteration: 700, loss: 0.9541947245597839\n",
      "epoch: 12, iteration: 800, loss: 0.7997401356697083\n",
      "epoch: 12, iteration: 900, loss: 0.9624534845352173\n",
      "epoch: 12, iteration: 1000, loss: 0.8261231184005737\n",
      "epoch: 12, iteration: 1100, loss: 0.9604076147079468\n",
      "epoch: 12, iteration: 1200, loss: 0.8593079447746277\n",
      "epoch: 12, iteration: 1300, loss: 0.9643322229385376\n",
      "epoch: 12, iteration: 1400, loss: 0.9246943593025208\n",
      "epoch: 12, iteration: 1500, loss: 0.9409468173980713\n",
      "epoch: 12, iteration: 1600, loss: 0.8881169557571411\n",
      "epoch: 12, iteration: 1700, loss: 0.8910125494003296\n",
      "epoch: 12, iteration: 1800, loss: 0.8736841678619385\n",
      "epoch: 12, iteration: 1900, loss: 0.8278210759162903\n",
      "epoch: 12, iteration: 2000, loss: 0.9004932045936584\n",
      "epoch: 12, iteration: 2100, loss: 0.8462778925895691\n",
      "epoch: 12, iteration: 2200, loss: 0.8079922795295715\n",
      "epoch: 12, iteration: 2300, loss: 0.8896111845970154\n",
      "epoch: 12, iteration: 2400, loss: 0.8595669269561768\n",
      "epoch: 12, iteration: 2500, loss: 0.870079517364502\n",
      "epoch: 12, iteration: 2600, loss: 0.8275396823883057\n",
      "epoch: 12, iteration: 2700, loss: 0.8289020657539368\n",
      "epoch: 12, iteration: 2800, loss: 0.8120294809341431\n",
      "epoch: 12, iteration: 2900, loss: 0.9340399503707886\n",
      "epoch: 12, iteration: 3000, loss: 0.8233143091201782\n",
      "epoch: 12, iteration: 3100, loss: 0.8222835659980774\n",
      "epoch: 12, iteration: 3200, loss: 0.8290935158729553\n",
      "epoch: 12, iteration: 3300, loss: 0.9186371564865112\n",
      "epoch: 12, iteration: 3400, loss: 0.9053552150726318\n",
      "epoch: 12, iteration: 3500, loss: 0.9175595045089722\n",
      "epoch: 12, iteration: 3600, loss: 0.8733409643173218\n",
      "epoch: 12, iteration: 3700, loss: 0.8152913451194763\n",
      "epoch: 12, accuracy: 0.9555\n",
      "epoch: 13, iteration: 0, loss: 0.8274660110473633\n",
      "epoch: 13, iteration: 100, loss: 0.8193058371543884\n",
      "epoch: 13, iteration: 200, loss: 0.834416925907135\n",
      "epoch: 13, iteration: 300, loss: 0.9768883585929871\n",
      "epoch: 13, iteration: 400, loss: 0.8352675437927246\n",
      "epoch: 13, iteration: 500, loss: 0.816904604434967\n",
      "epoch: 13, iteration: 600, loss: 0.8080697655677795\n",
      "epoch: 13, iteration: 700, loss: 0.9819505214691162\n",
      "epoch: 13, iteration: 800, loss: 0.7999361157417297\n",
      "epoch: 13, iteration: 900, loss: 0.8482707738876343\n",
      "epoch: 13, iteration: 1000, loss: 0.8625434041023254\n",
      "epoch: 13, iteration: 1100, loss: 1.005847454071045\n",
      "epoch: 13, iteration: 1200, loss: 0.8103623390197754\n",
      "epoch: 13, iteration: 1300, loss: 0.8284159898757935\n",
      "epoch: 13, iteration: 1400, loss: 0.94185870885849\n",
      "epoch: 13, iteration: 1500, loss: 0.8560684323310852\n",
      "epoch: 13, iteration: 1600, loss: 0.9335168600082397\n",
      "epoch: 13, iteration: 1700, loss: 0.8261383771896362\n",
      "epoch: 13, iteration: 1800, loss: 0.9014381170272827\n",
      "epoch: 13, iteration: 1900, loss: 0.9120557904243469\n",
      "epoch: 13, iteration: 2000, loss: 0.8476554155349731\n",
      "epoch: 13, iteration: 2100, loss: 0.8549467325210571\n",
      "epoch: 13, iteration: 2200, loss: 0.8371260762214661\n",
      "epoch: 13, iteration: 2300, loss: 0.8996244072914124\n",
      "epoch: 13, iteration: 2400, loss: 0.8720420598983765\n",
      "epoch: 13, iteration: 2500, loss: 0.8036139607429504\n",
      "epoch: 13, iteration: 2600, loss: 0.8407424688339233\n",
      "epoch: 13, iteration: 2700, loss: 0.8338840007781982\n",
      "epoch: 13, iteration: 2800, loss: 1.0871694087982178\n",
      "epoch: 13, iteration: 2900, loss: 0.8334917426109314\n",
      "epoch: 13, iteration: 3000, loss: 0.8238797187805176\n",
      "epoch: 13, iteration: 3100, loss: 0.8561981916427612\n",
      "epoch: 13, iteration: 3200, loss: 0.9050475358963013\n",
      "epoch: 13, iteration: 3300, loss: 0.8064519762992859\n",
      "epoch: 13, iteration: 3400, loss: 0.9266023635864258\n",
      "epoch: 13, iteration: 3500, loss: 0.9052762389183044\n",
      "epoch: 13, iteration: 3600, loss: 0.8056139349937439\n",
      "epoch: 13, iteration: 3700, loss: 0.8447107672691345\n",
      "epoch: 13, accuracy: 0.9579\n",
      "epoch: 14, iteration: 0, loss: 1.0695343017578125\n",
      "epoch: 14, iteration: 100, loss: 0.8419676423072815\n",
      "epoch: 14, iteration: 200, loss: 0.9537546038627625\n",
      "epoch: 14, iteration: 300, loss: 0.8574879169464111\n",
      "epoch: 14, iteration: 400, loss: 0.8357900381088257\n",
      "epoch: 14, iteration: 500, loss: 0.8175772428512573\n",
      "epoch: 14, iteration: 600, loss: 0.8389845490455627\n",
      "epoch: 14, iteration: 700, loss: 0.9778772592544556\n",
      "epoch: 14, iteration: 800, loss: 0.842300295829773\n",
      "epoch: 14, iteration: 900, loss: 0.8154723048210144\n",
      "epoch: 14, iteration: 1000, loss: 0.8312827348709106\n",
      "epoch: 14, iteration: 1100, loss: 0.8486467599868774\n",
      "epoch: 14, iteration: 1200, loss: 0.8920775055885315\n",
      "epoch: 14, iteration: 1300, loss: 0.92779141664505\n",
      "epoch: 14, iteration: 1400, loss: 0.8516680002212524\n",
      "epoch: 14, iteration: 1500, loss: 0.9457995295524597\n",
      "epoch: 14, iteration: 1600, loss: 0.8832767605781555\n",
      "epoch: 14, iteration: 1700, loss: 0.8359058499336243\n",
      "epoch: 14, iteration: 1800, loss: 0.8300537467002869\n",
      "epoch: 14, iteration: 1900, loss: 0.8019671440124512\n",
      "epoch: 14, iteration: 2000, loss: 0.9415323734283447\n",
      "epoch: 14, iteration: 2100, loss: 0.9037429094314575\n",
      "epoch: 14, iteration: 2200, loss: 0.9177068471908569\n",
      "epoch: 14, iteration: 2300, loss: 0.8866388201713562\n",
      "epoch: 14, iteration: 2400, loss: 0.8241133093833923\n",
      "epoch: 14, iteration: 2500, loss: 0.924301028251648\n",
      "epoch: 14, iteration: 2600, loss: 1.013368844985962\n",
      "epoch: 14, iteration: 2700, loss: 0.8325717449188232\n",
      "epoch: 14, iteration: 2800, loss: 0.91676265001297\n",
      "epoch: 14, iteration: 2900, loss: 0.8876929879188538\n",
      "epoch: 14, iteration: 3000, loss: 0.8207228779792786\n",
      "epoch: 14, iteration: 3100, loss: 0.8647210001945496\n",
      "epoch: 14, iteration: 3200, loss: 0.9731391072273254\n",
      "epoch: 14, iteration: 3300, loss: 0.9559973478317261\n",
      "epoch: 14, iteration: 3400, loss: 0.8596926927566528\n",
      "epoch: 14, iteration: 3500, loss: 0.9347516298294067\n",
      "epoch: 14, iteration: 3600, loss: 0.8262485265731812\n",
      "epoch: 14, iteration: 3700, loss: 0.8267028331756592\n",
      "epoch: 14, accuracy: 0.9581\n",
      "epoch: 15, iteration: 0, loss: 0.8296224474906921\n",
      "epoch: 15, iteration: 100, loss: 0.8084833025932312\n",
      "epoch: 15, iteration: 200, loss: 1.0399410724639893\n",
      "epoch: 15, iteration: 300, loss: 0.9740310311317444\n",
      "epoch: 15, iteration: 400, loss: 0.8781057596206665\n",
      "epoch: 15, iteration: 500, loss: 0.9789677858352661\n",
      "epoch: 15, iteration: 600, loss: 0.8085853457450867\n",
      "epoch: 15, iteration: 700, loss: 0.869040310382843\n",
      "epoch: 15, iteration: 800, loss: 0.8302673101425171\n",
      "epoch: 15, iteration: 900, loss: 0.8673752546310425\n",
      "epoch: 15, iteration: 1000, loss: 0.9191893339157104\n",
      "epoch: 15, iteration: 1100, loss: 0.8074117302894592\n",
      "epoch: 15, iteration: 1200, loss: 1.178015112876892\n",
      "epoch: 15, iteration: 1300, loss: 0.8262630105018616\n",
      "epoch: 15, iteration: 1400, loss: 0.9350618124008179\n",
      "epoch: 15, iteration: 1500, loss: 0.9232982397079468\n",
      "epoch: 15, iteration: 1600, loss: 0.8050612211227417\n",
      "epoch: 15, iteration: 1700, loss: 0.847891628742218\n",
      "epoch: 15, iteration: 1800, loss: 0.868086576461792\n",
      "epoch: 15, iteration: 1900, loss: 0.806428074836731\n",
      "epoch: 15, iteration: 2000, loss: 0.8126001954078674\n",
      "epoch: 15, iteration: 2100, loss: 0.9432551860809326\n",
      "epoch: 15, iteration: 2200, loss: 0.9216497540473938\n",
      "epoch: 15, iteration: 2300, loss: 0.9037876129150391\n",
      "epoch: 15, iteration: 2400, loss: 0.8017135858535767\n",
      "epoch: 15, iteration: 2500, loss: 0.7990906834602356\n",
      "epoch: 15, iteration: 2600, loss: 0.8290566802024841\n",
      "epoch: 15, iteration: 2700, loss: 0.847701907157898\n",
      "epoch: 15, iteration: 2800, loss: 0.8067675828933716\n",
      "epoch: 15, iteration: 2900, loss: 0.838249921798706\n",
      "epoch: 15, iteration: 3000, loss: 0.8069564700126648\n",
      "epoch: 15, iteration: 3100, loss: 1.025425910949707\n",
      "epoch: 15, iteration: 3200, loss: 0.7993149757385254\n",
      "epoch: 15, iteration: 3300, loss: 0.935430109500885\n",
      "epoch: 15, iteration: 3400, loss: 0.8479233384132385\n",
      "epoch: 15, iteration: 3500, loss: 0.8011338114738464\n",
      "epoch: 15, iteration: 3600, loss: 0.8627599477767944\n",
      "epoch: 15, iteration: 3700, loss: 0.8511027693748474\n",
      "epoch: 15, accuracy: 0.9581\n",
      "epoch: 16, iteration: 0, loss: 0.9263665080070496\n",
      "epoch: 16, iteration: 100, loss: 0.8507663011550903\n",
      "epoch: 16, iteration: 200, loss: 0.8089010119438171\n",
      "epoch: 16, iteration: 300, loss: 0.8597831726074219\n",
      "epoch: 16, iteration: 400, loss: 0.8227515816688538\n",
      "epoch: 16, iteration: 500, loss: 0.8209183812141418\n",
      "epoch: 16, iteration: 600, loss: 0.8226696848869324\n",
      "epoch: 16, iteration: 700, loss: 0.7983523011207581\n",
      "epoch: 16, iteration: 800, loss: 0.8332735300064087\n",
      "epoch: 16, iteration: 900, loss: 0.8195908069610596\n",
      "epoch: 16, iteration: 1000, loss: 0.9134401082992554\n",
      "epoch: 16, iteration: 1100, loss: 0.8702620267868042\n",
      "epoch: 16, iteration: 1200, loss: 0.8215855360031128\n",
      "epoch: 16, iteration: 1300, loss: 0.904250979423523\n",
      "epoch: 16, iteration: 1400, loss: 0.8389619588851929\n",
      "epoch: 16, iteration: 1500, loss: 0.8175637722015381\n",
      "epoch: 16, iteration: 1600, loss: 0.9689445495605469\n",
      "epoch: 16, iteration: 1700, loss: 0.8134307265281677\n",
      "epoch: 16, iteration: 1800, loss: 0.8187494277954102\n",
      "epoch: 16, iteration: 1900, loss: 0.8772136569023132\n",
      "epoch: 16, iteration: 2000, loss: 0.8189806938171387\n",
      "epoch: 16, iteration: 2100, loss: 1.0146477222442627\n",
      "epoch: 16, iteration: 2200, loss: 0.9294872283935547\n",
      "epoch: 16, iteration: 2300, loss: 0.8475444912910461\n",
      "epoch: 16, iteration: 2400, loss: 0.8134655952453613\n",
      "epoch: 16, iteration: 2500, loss: 0.8376372456550598\n",
      "epoch: 16, iteration: 2600, loss: 0.913940966129303\n",
      "epoch: 16, iteration: 2700, loss: 0.8740049600601196\n",
      "epoch: 16, iteration: 2800, loss: 0.9049174189567566\n",
      "epoch: 16, iteration: 2900, loss: 0.8009928464889526\n",
      "epoch: 16, iteration: 3000, loss: 0.8174604177474976\n",
      "epoch: 16, iteration: 3100, loss: 0.8130992650985718\n",
      "epoch: 16, iteration: 3200, loss: 0.8534034490585327\n",
      "epoch: 16, iteration: 3300, loss: 0.8076581954956055\n",
      "epoch: 16, iteration: 3400, loss: 0.8635326027870178\n",
      "epoch: 16, iteration: 3500, loss: 0.8737176656723022\n",
      "epoch: 16, iteration: 3600, loss: 0.8945964574813843\n",
      "epoch: 16, iteration: 3700, loss: 0.8075668811798096\n",
      "epoch: 16, accuracy: 0.961\n",
      "epoch: 17, iteration: 0, loss: 0.817753255367279\n",
      "epoch: 17, iteration: 100, loss: 0.8057643175125122\n",
      "epoch: 17, iteration: 200, loss: 0.9421752691268921\n",
      "epoch: 17, iteration: 300, loss: 0.8475788831710815\n",
      "epoch: 17, iteration: 400, loss: 0.8048588037490845\n",
      "epoch: 17, iteration: 500, loss: 0.8889183402061462\n",
      "epoch: 17, iteration: 600, loss: 0.8340224027633667\n",
      "epoch: 17, iteration: 700, loss: 0.8270705342292786\n",
      "epoch: 17, iteration: 800, loss: 0.9837700724601746\n",
      "epoch: 17, iteration: 900, loss: 0.850723385810852\n",
      "epoch: 17, iteration: 1000, loss: 1.0692682266235352\n",
      "epoch: 17, iteration: 1100, loss: 0.8168385028839111\n",
      "epoch: 17, iteration: 1200, loss: 0.9126862287521362\n",
      "epoch: 17, iteration: 1300, loss: 0.8289337158203125\n",
      "epoch: 17, iteration: 1400, loss: 0.8150671124458313\n",
      "epoch: 17, iteration: 1500, loss: 0.8100976347923279\n",
      "epoch: 17, iteration: 1600, loss: 0.8202558159828186\n",
      "epoch: 17, iteration: 1700, loss: 0.8176732659339905\n",
      "epoch: 17, iteration: 1800, loss: 0.8149290680885315\n",
      "epoch: 17, iteration: 1900, loss: 0.8304905891418457\n",
      "epoch: 17, iteration: 2000, loss: 0.8316017389297485\n",
      "epoch: 17, iteration: 2100, loss: 0.9721177816390991\n",
      "epoch: 17, iteration: 2200, loss: 0.8104895353317261\n",
      "epoch: 17, iteration: 2300, loss: 0.8131847977638245\n",
      "epoch: 17, iteration: 2400, loss: 0.8118234872817993\n",
      "epoch: 17, iteration: 2500, loss: 0.9125117659568787\n",
      "epoch: 17, iteration: 2600, loss: 0.8428459167480469\n",
      "epoch: 17, iteration: 2700, loss: 0.7989882230758667\n",
      "epoch: 17, iteration: 2800, loss: 0.8719339966773987\n",
      "epoch: 17, iteration: 2900, loss: 0.8028032779693604\n",
      "epoch: 17, iteration: 3000, loss: 0.8197481632232666\n",
      "epoch: 17, iteration: 3100, loss: 0.8194773197174072\n",
      "epoch: 17, iteration: 3200, loss: 0.817186176776886\n",
      "epoch: 17, iteration: 3300, loss: 1.1294441223144531\n",
      "epoch: 17, iteration: 3400, loss: 0.8352826237678528\n",
      "epoch: 17, iteration: 3500, loss: 0.8265127539634705\n",
      "epoch: 17, iteration: 3600, loss: 0.806077241897583\n",
      "epoch: 17, iteration: 3700, loss: 0.8139321804046631\n",
      "epoch: 17, accuracy: 0.9605\n",
      "epoch: 18, iteration: 0, loss: 1.0521912574768066\n",
      "epoch: 18, iteration: 100, loss: 0.9256842136383057\n",
      "epoch: 18, iteration: 200, loss: 0.8202155828475952\n",
      "epoch: 18, iteration: 300, loss: 0.8425679206848145\n",
      "epoch: 18, iteration: 400, loss: 0.8377913236618042\n",
      "epoch: 18, iteration: 500, loss: 0.805815577507019\n",
      "epoch: 18, iteration: 600, loss: 0.8120113015174866\n",
      "epoch: 18, iteration: 700, loss: 0.924033522605896\n",
      "epoch: 18, iteration: 800, loss: 0.8132690787315369\n",
      "epoch: 18, iteration: 900, loss: 0.8319348692893982\n",
      "epoch: 18, iteration: 1000, loss: 0.8460155725479126\n",
      "epoch: 18, iteration: 1100, loss: 0.8257839679718018\n",
      "epoch: 18, iteration: 1200, loss: 0.8277697563171387\n",
      "epoch: 18, iteration: 1300, loss: 0.9342219829559326\n",
      "epoch: 18, iteration: 1400, loss: 0.8269596099853516\n",
      "epoch: 18, iteration: 1500, loss: 0.8082351684570312\n",
      "epoch: 18, iteration: 1600, loss: 0.9311200976371765\n",
      "epoch: 18, iteration: 1700, loss: 0.8243910670280457\n",
      "epoch: 18, iteration: 1800, loss: 0.8298753499984741\n",
      "epoch: 18, iteration: 1900, loss: 1.0335742235183716\n",
      "epoch: 18, iteration: 2000, loss: 0.8017979264259338\n",
      "epoch: 18, iteration: 2100, loss: 0.80255126953125\n",
      "epoch: 18, iteration: 2200, loss: 0.8255562782287598\n",
      "epoch: 18, iteration: 2300, loss: 0.7994911670684814\n",
      "epoch: 18, iteration: 2400, loss: 0.9240133166313171\n",
      "epoch: 18, iteration: 2500, loss: 0.9725033044815063\n",
      "epoch: 18, iteration: 2600, loss: 0.841010332107544\n",
      "epoch: 18, iteration: 2700, loss: 0.8464387655258179\n",
      "epoch: 18, iteration: 2800, loss: 0.9377318024635315\n",
      "epoch: 18, iteration: 2900, loss: 0.9149447679519653\n",
      "epoch: 18, iteration: 3000, loss: 1.067392349243164\n",
      "epoch: 18, iteration: 3100, loss: 0.7992120981216431\n",
      "epoch: 18, iteration: 3200, loss: 0.9177127480506897\n",
      "epoch: 18, iteration: 3300, loss: 0.9325574636459351\n",
      "epoch: 18, iteration: 3400, loss: 1.0486202239990234\n",
      "epoch: 18, iteration: 3500, loss: 0.8189176321029663\n",
      "epoch: 18, iteration: 3600, loss: 0.8209720849990845\n",
      "epoch: 18, iteration: 3700, loss: 0.8308151364326477\n",
      "epoch: 18, accuracy: 0.9624\n",
      "epoch: 19, iteration: 0, loss: 0.9168038964271545\n",
      "epoch: 19, iteration: 100, loss: 0.8118890523910522\n",
      "epoch: 19, iteration: 200, loss: 0.8203831315040588\n",
      "epoch: 19, iteration: 300, loss: 0.8083839416503906\n",
      "epoch: 19, iteration: 400, loss: 0.8076033592224121\n",
      "epoch: 19, iteration: 500, loss: 0.8294678926467896\n",
      "epoch: 19, iteration: 600, loss: 0.857609748840332\n",
      "epoch: 19, iteration: 700, loss: 0.7987514734268188\n",
      "epoch: 19, iteration: 800, loss: 0.8036832213401794\n",
      "epoch: 19, iteration: 900, loss: 0.8135112524032593\n",
      "epoch: 19, iteration: 1000, loss: 0.7981815934181213\n",
      "epoch: 19, iteration: 1100, loss: 0.880504846572876\n",
      "epoch: 19, iteration: 1200, loss: 0.7980955839157104\n",
      "epoch: 19, iteration: 1300, loss: 0.8954418301582336\n",
      "epoch: 19, iteration: 1400, loss: 0.8004510402679443\n",
      "epoch: 19, iteration: 1500, loss: 1.0716489553451538\n",
      "epoch: 19, iteration: 1600, loss: 0.8955652117729187\n",
      "epoch: 19, iteration: 1700, loss: 0.9541200399398804\n",
      "epoch: 19, iteration: 1800, loss: 0.8233472108840942\n",
      "epoch: 19, iteration: 1900, loss: 0.8032634258270264\n",
      "epoch: 19, iteration: 2000, loss: 0.8715933561325073\n",
      "epoch: 19, iteration: 2100, loss: 0.9763311743736267\n",
      "epoch: 19, iteration: 2200, loss: 0.8012708425521851\n",
      "epoch: 19, iteration: 2300, loss: 0.919955849647522\n",
      "epoch: 19, iteration: 2400, loss: 0.902292013168335\n",
      "epoch: 19, iteration: 2500, loss: 0.809422492980957\n",
      "epoch: 19, iteration: 2600, loss: 0.8158963322639465\n",
      "epoch: 19, iteration: 2700, loss: 0.9325205087661743\n",
      "epoch: 19, iteration: 2800, loss: 0.8061168193817139\n",
      "epoch: 19, iteration: 2900, loss: 0.8234307169914246\n",
      "epoch: 19, iteration: 3000, loss: 0.9410017132759094\n",
      "epoch: 19, iteration: 3100, loss: 0.9057034850120544\n",
      "epoch: 19, iteration: 3200, loss: 0.8622934818267822\n",
      "epoch: 19, iteration: 3300, loss: 0.8691863417625427\n",
      "epoch: 19, iteration: 3400, loss: 0.9168466329574585\n",
      "epoch: 19, iteration: 3500, loss: 0.7988963723182678\n",
      "epoch: 19, iteration: 3600, loss: 0.801850438117981\n",
      "epoch: 19, iteration: 3700, loss: 0.8930744528770447\n",
      "epoch: 19, accuracy: 0.963\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n print(\\'=========================================\\')\\n    print(\"Model\\'s state_dict for epoch :\", i_epoch)\\n    for param_tensor in model.state_dict():\\n     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\\n\\n    print(\"Optimizer\\'s state_dict:\")\\n     for var_name in optimizer.state_dict():\\n      print(var_name, \"\\t\", optimizer.state_dict()[var_name])\\n\\n    print(\\'=========================================\\')\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\"\"\"\n",
    "TODO: 학습횟수를 자유자재로 바꾸어보자.\n",
    "\"\"\"\n",
    "\n",
    "for i_epoch in range(20):\n",
    "    train(model, train_loader, optimizer, i_epoch, device)\n",
    "    test(model, test_loader, i_epoch, device)\n",
    "    torch.save(model.state_dict(), \"mnist_test.pt\")\n",
    "\n",
    "\"\"\"\n",
    " print('=========================================')\n",
    "    print(\"Model's state_dict for epoch :\", i_epoch)\n",
    "    for param_tensor in model.state_dict():\n",
    "     print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "    print(\"Optimizer's state_dict:\")\n",
    "     for var_name in optimizer.state_dict():\n",
    "      print(var_name, \"\\t\", optimizer.state_dict()[var_name])\n",
    "\n",
    "    print('=========================================')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f661ca00d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#그래프 확인\n",
    "plt.plot(loss_value, label='Training Loss')\n",
    "\n",
    "plt.title('Training Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracy_value, label='Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "18b9409280c9003dfaaba2ea7df1148fd6b916133a0984877d999ff8976807a1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
